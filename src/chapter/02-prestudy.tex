\chapter{Preliminary Study}
% http://www-03.ibm.com/press/us/en/pressrelease/42451.wss

\minitoc

Review of relevant literature;
review of similar software products or tools.

I “survey”-kapittelet presenter en oversikt over tidligere relevant arbeid inkludert artikler og evt. eksisterende produkter.
Vurder kritisk styrker og svakheter av tidligere arbeid



This chapter is ment to outline the preliminary study of our project. This includes
    - what our technologies aims to achieve
    - how we will use them to achieve this.
Beyond this, the chapter will show the mythology the team chose to use and why this was a natural choice to go with. Research in software testing methods will be included and the best fit for this project. Since this is a prototype project, a considerable time is put into this part of the project, to assure the team makes good choices when it comes to technologies to use.

\clearpage

% \section{Set to work with (another name perhaps (or maybe completely removed))}
% About Netflix
\section{Movie recommendation}
This is the prestudy for the movie recommendation part of the system. We will look at existing recommendations systems, datasets to be explored and how to explore this set.


\subsection{Netflix}
% http://en.wikipedia.org/wiki/Netflix
% http://electronics.howdexstuffworks.com/netflix2.htm
% http://blog.jimjh.com/static/downloads/2013/05/12/netflix.pdf

\begin{wrapfigure}{r}{.30\textwidth}
\vspace{-30pt}
\centering
\includegraphics[width = .25\textwidth]{image/netflix-logo.png}
\end{wrapfigure}

Netflix is a on-demand Internet streaming media. It started out as a DVD-rental business, but moved over to a more Internet based business model in 1999 and have from then on had a great success in the subscription-based digital distribution service. To improve customer satisfaction they developed a personalized video-recommendation system called Cinematch. About 60\% of the Neflix users select their next movie or TV-show based on this recommendation[------------------2---------------], so it is important that this recommendation system manages to capture the users movie and TV-show preferences and feed back fitting movies and TV-shows.

\subsubsection{Cinematch}
\label{subsec:Cinematch}
% http://electronics.howstuffworks.com/netflix2.htm
This recommendation system is self-updating. It searches the Cinematch database for users who have rated the same movie, determents which of these again have rated a second movie and with this calculates likelihood that users who like the first also likes the second one.


\subsection{The Dataset}
% Pages used:
% http://www.timelydevelopment.com/demos/NetflixPrize.aspx
% http://dl.acm.org/citation.cfm?id=1536622&jmp=cit&coll=portal&dl=ACM#CIT
% http://www.the-ensemble.com/content/netflix-prize-movie-similarity-visualization
% http://en.wikipedia.org/wiki/Netflix_Prize
% http://blog.jimjh.com/static/downloads/2013/05/12/netflix.pdf
% http://en.wikipedia.org/wiki/Root-mean-square_deviation

Netflix held a competition where the contest was made to help Netflix improve their movie recommendation system. The team that could beat Netflix's own collaborative filtering system by more than 10\% could win one million dollars. To measure the score root-mean-square deviation (RMSE) was used, which is used to measure the difference between the values predicted or estimated and the actual values observed. The RMSE of Cinematch~\ref{subsec:Cinematch} was at 0,9525.

For this competition Netflix produced a training dataset based on user ratings from their own database. It contains 100 480 507 ratings from 480 189 unique users on 17 770 movies. The data is split up into 17 770 files, one for each movie, where the data is a triplet of the form <user, rating, date-of-rating>. The user-field and rating-field is an integer, while the date-of-rating-field is on the ISO 8601 form, year-month-day. The different movies have different amounts of ratings, and the different users have rated different amounts of movies.

With the training dataset the teams system was supposed to predict ratings on a "qualifying"-dataset, which contained 2 817 131 triplets with only user ids, movie ids and dates. This "qualifying"-datase must be disregarded since the actual ratings for this dataset was only know to the jury of the competition and is nowhere to be found. Instead a probe set is provided with 1 408 385 users which can be used to remove these from the training set to test predictions based on the test set. This probe set possesses similar statistical values as the qualifying set, so it will give a good prediction of how the result actually would have scored in the competition.

\begin{center}
\begin{tabularx}{\textwidth}{ l X }
\hline
\textbf{Ratings} & 100 480 507 \\ \hline
\textbf{Customers} & 480 189 \\ \hline
\textbf{Movies} & 17 770 \\ \hline
\textbf{Qualifying set} & 2 817 131 \\ \hline
\textbf{Probe set} & 1 408 385 \\ \hline
\end{tabularx}
\captionof{table}{Dataset statistics}\label{tab:nfDatasetStat}
\end{center}


\subsubsection{Dataset statistics}
% http://en.wikipedia.org/wiki/Principal_components_analysis
% http://en.wikipedia.org/wiki/Singular_value_decomposition
% http://en.wikipedia.org/wiki/Latent_semantic_indexing
% http://www.timelydevelopment.com/demos/NetflixPrize.aspx

To better understand the dataset, some statistics about the dataset was produced.

\begin{figure}[H]
\includegraphics[width=5in]{image/ratingdistr.png}
\centering
\caption{Rating distribution}
\label{figure:ratingdistr}
\end{figure}

Rating distribution is shown in figure~\ref{figure:ratingdistr}. 1/3 of the ratings are 4, and rating 1 and 2 only makes up for 13\% of the rating distribution. 3 and 5 are quite similarly represented with 28\% and 26\% respectively. It can from this be assumed a greater prediction towards the higher ratings, and predictions towards lower ratings should not be done lightly.

\begin{figure}[H]
\includegraphics[width=5in]{image/avgratingdistr.png}
\centering
\caption{Average rating distribution}
\label{figure:avgratingdistr}
\end{figure}

\begin{figure}[H]
\includegraphics[width=5in]{image/avgratdistrover.png}
\centering
\caption{Average rating distribution}
\label{figure:avgratdistrover}
\end{figure}


Average rating distribution is shown in figure~\ref{figure:avgratingdistr}. The upper graph shows average rating distribution of the customers, while the bottom one shows the distribution per movie. Both graphs have quite similar form. Both customers and movies peak at a rating of 3,5, which is natural. The second second highest point is for the customers at 4 and movies at 3, which is interesting to see. TO ANALYSE MORE!


\begin{figure}[H]
\includegraphics[width=5in]{image/avgmovierating.png}
\centering
\caption{Average movie rating distribution}
\label{figure:avgmovierating}
\end{figure}

Average movie rating distribution is shown in figure~\ref{figure:avgmovierating}. Here we see that for the edge ratings (rating 1 or 5) has the least standard deviation, so when a movie is highly rated it usually is rated high, and the same goes for low ratings, while for the middle ratings (2 to 4) we see that it variates more, and quite similarly. So the middle ratings are harder to classify, in other words, when a movie has a rating of 3, the average rating-shift is almost 1.1, so it must be expected that there is a bigger classification hit on these, so the problem will be to fin the right classification.


% About Classification
\subsection{Classification}
% http://www.netflixprize.com/assets/GrandPrize2009_BPC_PragmaticTheory.pdf
% http://www.netflixprize.com/assets/GrandPrize2009_BPC_BellKor.pdf
% http://www.netflixprize.com/assets/GrandPrize2009_BPC_BigChaos.pdf
% http://www2.research.att.com/~volinsky/netflix/Bellkor2008.pdf
% http://public.research.att.com/~volinsky/netflix/cfworkshop.pdf
% http://public.research.att.com/~volinsky/netflix/BellKorICDM07.pdf
% http://www2.research.att.com/~volinsky/netflix/ProgressPrize2007BellKorSolution.pdf
% http://public.research.att.com/~volinsky/netflix/sigkddexp.pdf
% http://www.netflixprize.com//leaderboard
% https://sites.google.com/site/xlvector/netflixprize/papers

% https://github.com/cloudera/oryx

TODO:
There are two basic problems when analysing very large datasets:
    - Writing the code correctly.
    - The performance (i.e. speed at which it runs).


Something about why and which classification alg to use

\subsection{What the top Netflix-Prize contestants did}

\subsubsection{BellKor}
asdf


\subsubsection{Conclusion}
% End Classification



\subsection{Algorithms to solve the problem}
% http://scenic.princeton.edu/network20q/wiki/index.php?title=Q4:_How_does_Netflix_recommend_movies%3F
% http://blog.jimjh.com/static/downloads/2013/05/12/netflix.pdf
There were 51 051 contestants on 41 305 different teams competing in the Netflix-Prize competition, and a lot of these contestants shared their solution through code repositories such as GitHub (--------------something about github here?--------------). Since many of these solution scored very well on the contest it was natural to explore these and use their solution to test potential improvement in collaboration with social media data.
Here we explore some of the better solutions and how and why these could be used to our benefit.

https://github.com/n8j/school/tree/master/DataMiningCSEP546/HW1



BellKor's Pragmatic Chaos - RMSE = 0.8567

% End Netflix



% About Weka
\section{Weka}
%http://en.wikipedia.org/wiki/Weka_(machine_learning)

\begin{wrapfigure}{r}{.30\textwidth}
\vspace{-30pt}
\centering
\includegraphics[width = .25\textwidth]{image/Weka-logo.png}
\end{wrapfigure}


Weka is a machine learning software written in Java. It can be used to visualize data through analyzing it with different kinds of algorithms. The Explorer, a graphical user interface, makes it easy to work with and explore data from different angles. It is a free software under the General Public License [].
%http://en.wikipedia.org/wiki/GNU_General_Public_License
Weka can handle several data mining tasks, including, data preprocessing, clustering, classification, regression and feature selection. The input data has to be a single flat file or relation, each data point must be described by a fixes number of attributes. The dataset can be accessed trough a SQL database. Can link database tables into a single datatable, which can be used for processing using Weka.

\subsection{The Explorer}
% http://www.cs.waikato.ac.nz/~ml/weka/gui_explorer.html
% http://research.cs.queensu.ca/home/cisc333/tutorial/Weka.html
% http://wiki.pentaho.com/display/DATAMINING/Time+Series+Analysis+and+Forecasting+with+Weka
TODO: TABLE OF EXPLORER PROPERTIES? TOO MUCH?

\subsection{ARFF}
% http://www.cs.waikato.ac.nz/ml/weka/arff.html
Attribute Relationship File Format is the file type used to store data in a database. The structure is as follows:

\begin{lstlisting}[caption={ARFF Example},captionpos=b,label={lst:arffEx},numbers=left]
@relation 'flat-netflix'

@attribute assetId string
@attribute 14367 numeric
@attribute 6050 numeric
@attribute 14112 numeric

@data
1658496,?,?,4
684232,3,3,?
684231,4,?,?
1774519,1,?,?
\end{lstlisting}

Listing~\ref{lst:arffEx} is an example of how an ARFF file is structured. It startes with a header, containing "@relation", "@attribute"s and the "@data". This header defines the name of the relation, the attributes in the dataset and the data. The "@data"-header contains arrays, where each array has values for the corresponding "@attribute"s values. If a array has no value for a particular attribute it is denoted as a question mark (?).
% End Weka




% About Twitter
\section{Twitter}

\begin{wrapfigure}{r}{.30\textwidth}
\vspace{-30pt}
\centering
\includegraphics[width = .25\textwidth]{image/twitter-logo.png}
\end{wrapfigure}

TODO:
Describes the existing stuff from twitter and twitter-api
\subsection{Twitter-API}
% End Twitter




\section{Similar solutions (Evaluation of State-of-the-art)}
TODO:
In this section, we will discuss similar solutions and their relevance to our project.

If this is not state of the art stuff, maybe separate this and that




\section{Development language and technologies (maybe not needed)}

\subsection{Database}
For the system we need some kind of persistent storage, a database where the harvested data from the Twitter-harvesting is stored so it only is needed to fetch once, and where the data from the Netflix-prize set is stored. This Database will be ran from a personal computer to start with, TODO: SOMETHING ABOUT THE HARVEST IS DONE; OR REFERING TO THE TWITTER CHAPTER, since it is not needed to be constantly running. For the database we are left with a decision between traditional SQL database or a so called NoSQL database. The differences are explained below.

\subsubsection*{NoSQL}
% http://en.wikipedia.org/wiki/NoSQL
NoSQL databases can be defined as: being non-relational, distributed, open-source and horizontally scalable\cite{nosql}. NoSQL is meant for storing large amounts of data\cite{bigdata}, where all the data does not share the same attributes or schema. They are focusing on eventually consisten(BASE) instead of the SQL ACID \cite{pritchett}. The different kinds of NoSQL databases have different ways of classifying the database, some of the more used ones are: key-value, column, document, graph and relational.

\begin{table}
\centering
\begin{adjustwidth}{-2cm}{}
\begin{tabularx}{1.3\textwidth}{  l l l l l l }
  \textbf{Data Model} & \textbf{Performance} & \textbf{Scalability} & \textbf{Flexibility} & \textbf{Complexity} & \textbf{Functionality}\\
  \hline \\ [-1.5ex]
  Key-value & high      & high              & high      & none      & variable (none)\\
  \hline \\ [-1.5ex]
  Column    & high      & high              & moderate  & low       & minimal \\
  \hline \\ [-1.5ex]
  Document  & high      & variable (high)   & high      & low       & variable (low)\\
  \hline \\ [-1.5ex]
  Graph     & variable  & variable          & high      & high      & graph theory \\
  \hline \\ [-1.5ex]
  Relational & variable & variable          & low       & moderate  & relational algebra\\
\end{tabularx}
\end{adjustwidth}
\caption{Classification based on feature}
\label{table:nosql-calssifications}
\end{table}
% http://www.slideshare.net/bscofield/nosql-death-to-relational-databases
As we can see from table~\ref{table:nosql-calssifications} performance, scalability and flexibility are usually rated as high in all the categories. Relational algebra in the database will not be needed for the project to succeed so that category can be disregarded. High flexibility in the database would also be a feature sought after when going for NoSQL, so the column storage can also be eliminated from the equation. TODO: MAYBE SOMETHING MORE HERE lol the tree left are described well here : http://en.wikipedia.org/wiki/NoSQL
% http://en.wikipedia.org/wiki/Comparison_of_structured_storage_software
% http://www.mongodb.org/
\cite{nosql-databases, nosql-article}


\subsubsection*{SQL}
SQL database is the most common way of storing data. The data is stored in columns and tables. The database can make relations between the tables id necessary, hence relational databases. A main focus in SQL databases is queries and optimizing these where there usually exists some king of structured language to fetch the wanted data. The basic operations, which can be found in most SQL databases, are SELECT, UPDATE, REMOVE and INSERT. This kind of database is schema defined and follows the ACID(atomicity, consistency, isolation, durability) principles.
\cite{ramakrishnan2003database}




\subsubsection{Database Alternatives}
TODO WHEN EXPLORED THE THREE NOSQL CATEGORIES LEFT, IF THEY ARE TO BE EXPLORED
Below, some of the database implementation available to us are discussed. We mainly investigated document NoSQL databases and regular SQL databases. The most appealing options are introduced below.


\subsubsection*{MongoDB}
MongoDB is a large scale, high availability, robust system. It is a document NoSQL system, so instead of storing the data in tables as you would in MySQL, the data is stored in a document based fashion through for instance JSON with dynamic schemas. This makes the DB easier scalable horizontally. But the mongoDB still possesses the some of the great properties from relational databases, such as indexes, dynamic queries and updates. With mongoDB it is easy to map objects to programming language data types, which makes the DB easy to work with. The embedded documents and arrays makes the join operations less importance, which result in the ability to make reads and writes faster. JavaScripts can also be included in the queries. This makes mongoDB an efficient and high speed data base for storing objects and fetching to a system. MongoDB also has its own access console, where you can use scripting with Javascript language. \cite{mongodb-intro}


\subsubsection*{CouchDB}
CouchDB stores the data in JSON documents(NoSQL) object-oriented, which can be accessed through HTTP. The data documents can be transformed and data fetched with JavaScript. CouchDB has a lot of built in features which makes web development with CouchDB easier. It scales well through replication and is a consistent system, where CouchDB prioritizes the data of the user. CouchDB is multiversion concurrency control based, this is good for intense versioning, offline databases which resync later and master to master replication. The interface to the database is REST based, which is a useful feature when you are developing a web- application.
\cite{couchdb-about, couchdb-technical}


\subsubsection*{MySQL}
MySQL is the most popular database in the world of open databases. This is because of its high performance, reliability and ease of use. It should therefore be considered for the question of which database system to use. In opposition of the two database systems described above, MySQL is a relational database. This makes it more troublesome to work, with when it comes to JavaScript, than the other two. It is not as well integrated with JSON and will need parsing to be able to work with the clients. This alone is a hard negative towards MySQL.
\cite{mysql-about}





\subsubsection{Conclusion}
One particular type of NoSQL databases that caught our attention early was the document NoSQL databases.
The main characteristic of these databases is their schema- less structure.
They also differ from SQL by generally not using a structured query language for data manipulation.
They are easy to replicate and they offer simple APIs for the clients to communicate with.
They are heavily customized for web- applications, and have gained much popularity in the modern web era.
Most document NoSQL databases focus on quick replies to requests, as the query operation is by far the most common in a typical web- application.
Because they typically are distributed, NoSQL databases are able to store enormous amounts of data, and they are often used within Big Data\cite{bigdata} applications like Hadoop\cite{hadoop}, which recently has become a very popular subject within the computer science community.

TODO: MAKE OUR OWN :p
We decided to go for CouchDB in this project. We are working in a web domain, which CouchDB was designed for. While developing the console we will be working closely with JavaScript objects, and try to find ways of exposing these to the users. JavaScript objects are easily converted to JSON, the format used to store data in document NoSQL databases like MongoDB and CouchDB.  As we only have the need to store the actual objects and a limited amount of relations between them, using CouchDB will ease our work considerably, and allow us to do things which would not be possible with a regular SQL database. CouchDB imposes far less restrictions on how you store your data than traditional SQL does. As long as the data is represented in JSON, you can store pretty much store anything you like, even within the same database. This will give us great flexibility when it comes to adding information to specific objects, and also means that objects of the same type can contain different attributes without us needing to create a new schema or change anything in the database. It also gives the user great flexibility in the sense that they can add any information they would like to the different objects, and we the developers don't have to plan for it at all, the database does all this for us. The fact that the customer suggested to us that we could use a NoSQL database, also tipped the scale in direction of the NoSQL alternatives.

Relational databases is the traditional way to deploy databases and they are in widespread use. In many situations they are extremely useful. However relational databases requires you to morm your data up front, before you save anything to the database. Failing to comply with these restrictions will lead to failure, and it is sometimes difficult to create this kind of morm that actually fits real world data. Even though objects may share common attributes, there are bound to be some attributes that are different. This is difficult to plan for in advance, and its the main reason we will not be using a SQL database for this project. For the database, we originally chose to use MongoDB as our document NoSQL database. This was due to the fact that it was better documented and seemed better suited for the system as we originally planned it. Some of the features CouchDB offered wasn't thought of as necessary for the project at the time. During the implementation process we however came to the conclusion that CouchDB actually was a better fit. This was mostly due to its ability to act as an standalone system on a server without the need for other supporting server technologies like Node.js or ASP.NET. Also, the fact that it automaticly creates a RESTful API to access the database turned out to save us a lot of time. As a result of these discoveries we changed to CouchDb during the third sprint.









\subsection{Programming languages}
TODO something about the languages to use and why!
Dependent on:
    weka
    twitter api
    solution used to solve netflix api
    database to choose
    future thoughts


Our main focus will be on the client part of the application, since this is the experimental part of our system, and it is this part that is visible to the user through the web browser. It is therefore important to choose a suitable technology for this.


\subsubsection{JavaScript}

JavaScript is a scripting language supported by all popular web browsers. Has extensive frameworks built around it and allows for rapid development. It is also possible to let the user write commands using JavaScript directly.

\subsubsection{Conclusion}
As a team, we have extensive experience with Java, and less with the other technologies. However, we all have at least some experience with JavaScript, and we believe that it is the better choice for this project: The DSL can be implemented by allowing the user to perform operations on the JavaScript objects using (a subset of) the JavaScript language itself. There are also excellent tools for transfer and storage of JavaScript objects. Furthermore, communication between JavaScript and HTML elements is easily achieved.






\section{Software Testing}
TODO: CHAPTER NOT THAT NECCESSARY PERHAPS?

\subsection{Testing Methods}
The purpose of software testing is to uncover software bugs in the system and to document that the system meet the requirements and functionality that was agreed upon for the system. Testing can be implemented at any stage in the development process, traditionally it is performed after the requirements have been defined and the implementation is completed. In agile development processes however, the testing is an ongoing process. The chosen development methodology will in most cases govern the type of testing implemented in a given project.
\cite{sommerville2011software}

Software testing methods are traditionally divided into white- and black- box testing. They differ mainly in how the test engineer derives test cases.

\subsubsection{White- Box Testing}
White- box testing focus on the internal structures of a system, and it uses this internal perspective to derive test cases. White- box testing is usually done at unit level, testing specific parts or components of the code. This kind of testing focus on how something is implemented and not necessarily why. Unit testing alone cannot verify the functionality of a piece of software is supposed to exhibit. It can uncover many errors or problems, but it might not detect unimplemented parts of the specification or missing requirements.

\subsubsection{Black- Box Testing}
Black- box testing handles the software as a black- box, meaning it observes the functionality the system exhibits and not the specifics on how it is implemented. The tester only needs to be aware of what the program is supposed to do, he doesn't need to know the specifics on how the functionality is implemented in the code. Black- box testing is typically performed to check if the functionality of the program is according to the agreed upon requirements, both functional and nonfunctional. Black- box testing is usually done at the component, system and release levels of testing. The main advantage of black- box testing is that no programming knowledge is needed to actually perform the tests. This way you can hire someone outside the development team who has had nothing to do with the implementation of the code to write and perform the tests, and you achieve as little ownership of the code as possible. An argument can be made though that this lack of insight in the specifics of the source code will result in repeated testing of some parts of the code, while other parts could be left untested.

\subsubsection{Test Driven Development}
The principle behind TDD is to develop the code incrementally, along with test for that increment. You don’t move on until the code passes its test. The tests are to be written before you actually implement the new functionality. The process helps programmers clarify their ideas of what a code segment is actually supposed to do. The process is often used in agile development methods.
Benefits from TDD include:
\begin{itemize}

\item Code coverage, every code segment should be covered at least one test.

\item Regression testing, check to see if changes in the code have not introduced new bugs.

\item Simplified debugging, when a test fails it should be obvious where the problem lies, no need for a debug tool.

\item System documentation, the tests themselves act as a form of documentation that describe what the code should be doing.

\end{itemize}

\cite{beck2003test-driven}

\subsubsection{Automated Tests}
Automated offers the ability to automatically do regression tests, i.e. testing to uncover if any new code has broken a test that previously passed. If we opt for manual testing regression testing will be very time consuming as every test done so far has to be done over again. With an automated testing framework this job will be a lot easier as you can run a great number of tests in a matter of seconds. Most development languages offers libraries for automated testing.


\subsection{Testing Levels}
Testing can be done at many different levels and in different stages in the development process. Following is the most common partitioning of testing levels and a description on each of them.

\subsubsection{Unit Testing}
Unit testing aims to check specific components, such as methods and objects. Typically you will be testing objects, and you should provide test coverage of all the features of that object. Its important to choose effective unit test cases, that reflect normal operation and they should show that the specific component works. Abnormal inputs should also be included to check if these are processed correctly.

\subsubsection{Component Testing}
Tests bigger components of the system, and their interfaces(communication with other components). Made up of several interacting objects. Component testing is mainly a tool to check if component interfaces behaves according to its specification.

\subsubsection{System Testing}
In a given development project there may be several reusable components that have been developed separately and COTS systems, that has to be integrated with newly developed components. The complete system composing of the different parts is tested at this level. Components developed by different team members or groups may also be integrated and tested at this stage.

\subsubsection{Release Testing}
Release testing is the process of testing a particular release of the system that is intended for use outside of the development team. Often a separate team that has not been involved in the development perform this testing. These kind of tests should focus on finding bugs in the complete system. The objective is to prove to the customer that the product is good enough. This kind of testing could either be based on the requirements of the system or on user scenarios.

\subsubsection{User Testing}
This is a stage in the testing process in which users or customers provide feedback and advice. This could be an informal process where end- users experiment with a new system too see if they like it and that it conforms to their specific needs. Testing on end- users is essential for achieving success in a software process as replicating the exact working environment the system will be used in is difficult to achieve during development. The end users can help provide feedback on how specific functionality will work in an actual work environment.

Another form of user testing involves the customer and its called acceptance testing. Its a process where the customer formally tests a system to decide whether or not it should be accepted, where acceptance implies that payment for the system should be made. Acceptance testing is performed after the release testing phase.

\subsection{Conclusion}
The concept of TDD is to develop exhaustive tests that specify the system, and then writing code with the goal of satisfying the tests. This is useful in systems where the key functionality is in the form of program logic that can be verified to conform to the specification. It is difficult to write such exhaustive tests in applications that rely heavily on GUIs, network connections and database systems because of the added complexity and heterogeneousness that these features involve. In addition, our prototype's exact specifications are likely to change during development, requiring large amounts of test rewriting in the case of TDD, because the tests will be more numerous and because the tests must be more strict. As a result we have opted not to use TDD in this project. We will however be utilizing unit tests with an automated testing framework where it is appropriate and will harvest some of the advantages linked to TDD, like the automated regression testing.

We will be writing unit tests throughout the implementation process and run these continuously. These tests will not be included in the report as test cases. The test cases will rather comprise of component and system tests. Component tests will be used to test specific components and their functionality as well as their interaction with other components. System tests will be used on the system as a whole to check if it meets the agreed upon requirements. These test cases will be derived from the requirements. We will also try include some acceptance tests to include the customer in the testing process.

We will be utilizing user testing and involve end users to get feedback on the entire system or specific functions. This testing will mainly be used to get feedback on the domain scripting language and how easy it is to understand and use. Preferably it will be done continuously throughout the development process. It is important to involve users as the goal of this project is to ease their workflow. As we are not working with an existing system thats actually in use, there will not exist any real users of this system with experience using it. We will therefore mainly be using our fellow students as test subjects, as they are readily available and technically competent enough to understand the concept and act as superusers. In addition the customer has stated that it will encourage employees from the entire company to us give feedback if we ask for it. Specific solutions can be sent to the customer representative which in turn will relay it to experts on the area it concerns.


\section{Result Testing}
TODO: HERER OR IN THE REQ-CHAP?

\section{Evaluation (maybe)}
TODO:
To sum up what we saw after the prestudy
